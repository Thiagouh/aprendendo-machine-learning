---
title: 'Vetoriza√ß√£o'
pubDate: 2025-12-20
description: 'Aqui veremos a fundo a import√¢ncia da vetoriza√ß√£o'
heroImage: '/images/vetorizacao_numpy.png'
---
import Callout from '../../../components/Callout.astro'

<Callout type="info" title="Antes de Come√ßar: Python B√°sico">
√â importante salientar inicialmente que ser√£o necess√°rios alguns conhecimentos b√°sicos sobre Python para entender o Blog sem boiar muito. Ent√£o se voc√™ nunca viu nada de Python, eu recomendo os seguintes conte√∫dos para estudo (ou apenas se quiser ver o que foi utilizado no blog):

* **[Python para Estat√≠sticos](https://tmfilho.github.io/pyestbook/intro.html):** Este livro, do professor Telmo de Menezes e Silva Filho, do Departamento de Estat√≠stica da UFPB √© um √≥timo guia para quem quer aprender Python. Foi essencial para o meu processo seletivo da TAIL e vai direto ao ponto no que tange a programa√ß√£o voltada para dados.
* **[Kaggle](https://www.kaggle.com/learn):** O Kaggle √© a maior comunidade de Data Science do mundo. A se√ß√£o de cursos deles √© perfeita se voc√™ quer praticidade: s√£o minicursos gratuitos que rodam direto no navegador e focam exclusivamente nas ferramentas que iremos usar em Machine Learning, ignorando o que n√£o √© essencial agora. 
 </Callout>

 <style>{`
  table {
    width: 100%;
    border-collapse: collapse;
    margin: 20px 0;
    font-size: 0.95rem;
  }
  th {
    background-color: #f4f4f4;
    border-bottom: 2px solid #ddd;
    text-align: left;
    padding: 12px;
  }
  td {
    padding: 10px 12px;
    border-bottom: 1px solid #eee;
  }
  tr:nth-child(even) {
    background-color: #fafafa;
  }
`}</style>

Nos posts anteriores, vimos a seguinte f√≥rmula da Regress√£o Linear M√∫ltipla:

$$
f_{w,b}(x) = \vec{w} \cdot \vec{x} + b
$$

Matematicamente isso √© perfeito. Mas, computacionalmente, isso pode ser um pesadelo se tivermos que resolver termo a termo milh√µes de dados (tipo quando $n = 5.000.000$).

Se voc√™ j√° programou em alguma linguagem de programa√ß√£o, sua intui√ß√£o mandaria utilizar um loop ```for``` para percorrer todos os dados e som√°-los. Por√©m, em Python, para Machine Learning, evitamos utiliz√°-lo.

### Por que evitar loops em Python?
Python √© uma linguagem interpretada e din√¢mica. Ou seja, a cada vez que o loop roda, o programa ir√° verificar o tipo da vari√°vel, alocar mem√≥ria e executar a soma. Isso acaba gerando uma sobrecarga enorme principalmente se houver uma enorme quantidade de dados a serem processados pelo loop.

## Introdu√ß√£o a Vetoriza√ß√£o (NumPy)
Ent√£o se utilizar loops n√£o √© a melhor abordagem para esse caso, temos uma alternativa perfeita para essa situa√ß√£o que √© justamente a **Vetoriza√ß√£o**. A vetoriza√ß√£o permite que o nosso computador execute opera√ß√µes em conjuntos de dados inteiros de uma s√≥ vez. Isso acontece por meio de instru√ß√µes de baixo n√≠vel na CPU chamado SIMD (Single Instruction, Multiple Data).

Para usar isso em Python, utilizamos a biblioteca **NumPy**.

### A compara√ß√£o: Loop vs Vetoriza√ß√£o
Se voc√™ ainda n√£o acredita em mim, te provarei agora que o loop ```for``` √© mais lento que a vetoriza√ß√£o! (e tamb√©m aprender√° como utilizar a vetoriza√ß√£o). Vamos, portanto, simular o c√°lculo do modelo $\mathbf{w} \cdot \mathbf{x}$ (Produto Escalar).

#### A implementa√ß√£o com loop (lenta)
Come√ßaremos com a implementa√ß√£o do loop ```for```. Vamos percorrer cada elemento dos vetores 'w' e 'x' multiplicando-os e somar tudo.

```python
import time

# 1 milh√£o de features como dados simulados
w = [i * 0.0001 for i in range(1000000)]
x = [i * 0.0001 for i in range(1000000)]

def produto_escalar_loop(w, x):
  resultado = 0
  for i in range(len(w)):
    resultado += x[i] * w[i] # Produto Escalar
  return resultado

start = time.time()
resultado_final = produto_escalar_loop(w, x)
end = time.time()

print(f"Tempo com loop: {end - start:.5f} segundos.")
```

#### A implementa√ß√£o vetorizada (r√°pida)
Aqui temos a nossa implementa√ß√£o visada em performance. Veja que o c√≥digo tamb√©m fica menor e mais limpo utilizando o m√©todo de vetoriza√ß√£o.

```python
import numpy as np
import time

w = [i * 0.0001 for i in range(1000000)]
x = [i * 0.0001 for i in range(1000000)]

# A convers√£o para array √© necess√°ria para o NumPy 
# trabalhar
w_np = np.array(w)
x_np = np.array(x)

start = time.time()
resultado = np.dot(w_np, x_np) # Produto Escalar
end = time.time()

print(f"Tempo com vetoriza√ß√£o: {end - start:.5f} segundos.")
```

##### **üìä Resultado da Compara√ß√£o**

| M√©todo | Tempo de Execu√ß√£o | Performance |
| :--- | :--- | :--- |
| Loop `for` (Python) | 0.05918s | 1x (Base) |
| **Vetoriza√ß√£o (NumPy)** | **0.00186s** | **~32x mais r√°pido** |

Note que a implementa√ß√£o vetorizada √© muito mais r√°pida (sim, por millisegundos. Mas ainda √© ~32x mais r√°pido a vetoriza√ß√£o em rela√ß√£o ao loop).

## Conex√£o com a Matem√°tica 
Lembra da f√≥rmula matem√°tica que vimos no Blog passado que envolvia o Produto Escalar ($f_{\mathbf{w},b}(\mathbf{x}) = \mathbf{w} \cdot \mathbf{x} + b $)? A vetoriza√ß√£o permite traduzir essa matem√°tica diretamente para o c√≥digo. Em vez de escrevermos 10 linhas de loop, podemos simplesmente escrever:

```python
f = np.dot(w, x) + b
```

Dessa forma o c√≥digo ficar√° muito mais limpo, organizado e r√°pido.

## Por tr√°s dos bastidores
√â muito interessante como algoritmos com e sem vetoriza√ß√£o, apesar de terem o mesmo prop√≥sito, apresentam velocidades de execu√ß√£o t√£o distintas. Para podermos entender melhor como isso √© poss√≠vel, precisamos entender como ambos os algoritmos funcionam computacionalmente.

### Sem vetoriza√ß√£o

Como vimos anteriormente, na abordagem sem vetoriza√ß√£o utilizamos o ```for``` loop para percorrer os dados. A quest√£o √© que o processador executa uma itera√ß√£o por vez, sequencialmente.

```python
import time

def dot_product_nao_vetorizado(w, x):
  f = 0
  # O loop imp√µe uma ordem sequencial r√≠gida
  for j in range(len(w)):
      # O processador precisa buscar w[j] e x[j], 
      # multiplicar, somar a 'f' e
      # s√≥ ent√£o passar para o pr√≥ximo j.
      f = f + w[j] * x[j] 
  return f
```

A linha do tempo seria basicamente:
* No tempo $t_{0}$, o computador busca o valor $w_{0}$ e $x_{0}$, multiplica e soma ao acumulador $f$.
* Somente ap√≥s terminar essa conta, ele avan√ßa para o pr√≥ximo tempo $t_{1}$, para processar o √≠ndice 1.
* Isso se repete at√© o √∫ltimo elemento ($t_{n}$).

Ou seja, para o vetor de 1.000.000 de elementos, o processador iria ter que realizar 1.000.000 ciclos dessa conta. Meio demorado, hein.

### Com vetoriza√ß√£o

Ao usarmos ```np.dot(w, x)```, essa l√≥gica muda completamente. diferente do loop ```for```, onde o Python processa um dado por vez, a vetoriza√ß√£o aproveita o hardware moderno para processar blocos inteiros de dados de uma s√≥ vez.

```python
import numpy as np

# Abordagem COM vetoriza√ß√£o 
# (SIMD: Single Instruction, Multiple Data)
def dot_product_vetorizado(w, x):
    # O Python delega tudo 
    # para o backend em C/Assembly otimizado
    return np.dot(w, x)
```

No c√≥digo acima, todas as multiplica√ß√µes acontecem paralelamente. Gra√ßas a Vetoriza√ß√£o, o hardware ataca grandes blocos de dados simultaneamente, reduzindo drasticamente as janelas de tempo necess√°rias.